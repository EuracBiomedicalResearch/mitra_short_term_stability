---
title: "Normalization of mitra short term stability data"
subtitle: "positive polarity"
author: "Christa Malfertheiner"
graphics: yes
output:
  BiocStyle::html_document:
    toc_float: true
bibliography: references.bib
csl: biomed-central.csl
references:
- id: dummy
  title: no title
  author:
  - family: noname
    given: noname
---

```{r biocstyle, echo = FALSE, results = "asis"}
library('knitr')
library(BiocStyle)
BiocStyle::markdown()
```

**Modified**: `r file.info("sts_normalization_pos.Rmd")$mtime`<br />
**Compiled**: `r date()`

```{r settings, echo = FALSE, results = "hide", message = FALSE}
## Set general options
options(useFancyQuotes = FALSE)
set.seed(123)
## Setting golden ratio to save images
phi <- (1+sqrt(5))/2
## Define paths:
filename <- "sts_normalization_pos"
## Path to save the images; remove all old images.
IMAGE_PATH <- paste0("images/", filename, "/")
dir.create(IMAGE_PATH, recursive = TRUE, showWarnings = FALSE)
## Path to store RData files
RDATA_PATH <- paste0("data/RData/", filename, "/")
if (!file.exists(RDATA_PATH)) dir.create(RDATA_PATH, recursive = TRUE)
## Define the path where we can find the mzML files:
## MZML_PATH <- "/data/massspec/mzML/"
## MZML_PATH <- "C:/Users/User/Documents/sts_mzML_pos"
## if (!file.exists(MZML_PATH))
##     stop("Can not find the directory with the mzML files: ", MZML_PATH)
## Get the number of cpus allocated or fall back to 3
ncores <- as.integer(Sys.getenv("SLURM_JOB_CPUS_PER_NODE", 4)) - 1L
```

# Abstract

This document defines the normalization of the feature abundance  on short term
stability data collected with mitra tips. This comprises a first quality
assessment, fill-in of missing values, between-sample normalization and
normalization of injection order-dependent signal drift within the measurement
run.

# Introduction

Untargeted metabolomics experiments are, similar to any other data from high
throughput assays, subject to unwanted variation: this can stem from many
sources, such as experimental equipment and unwanted technical or biological
differences among samples. The former kind of variation includes batch-to-batch
variation due to environmental conditions, such as temperature changes,
instrument performance, sample preparation and subsequent degradation. The
latter can arise from different weights or volumes of the samples or a different
size of cells among samples [@Livera:2015bo].

These effects are unavoidable and several methods have been developed to
accommodate them in statistical models or to remove them, as described in
[@Livera:2015bo]. Many algorithms are based on regression models to achieve the
goal of batch correction, while other approaches use scaling factors to remove
unwanted variation. The first type is used for example in the approach of
Wehrens et al. [@Wehrens:2016ie] to perform a featyre-wise normalization of
batch effects and signal drifts. This approach is however unable to account for
between-sample differences such as differences in volumes injected, which can
however be adjusted for by simple scaling methods. For this reason, the two
approaches can be combined to provide a better outcome for the normalization of
experimental measurements, in order to make the data more comparable.

In this document we perform the normalization of the feature abundances on short
term stability data collected with mitra tips.
This comprises quality assessment based on the features abundances, eventual
normalization of a injection order-dependent signal drift within each batch (if
this proves to increase signal quality as determined by the comparison of
abundances from replicated measurements). The preprocessing of the data is
described in file *sts_preprocessing_pos.Rmd*.

## Metabolomics data normalization

Untargeted meatabolomics data biased by a variety of different biological and
technical variances. Biological variances include e.g. the amount or
concentration of biofluids while technical variances comprise batch effects
(laboratory conditions, reagent lots), sample degradation over time in long runs
of samples, matrix specific effects (such as ion suppression), temperature
changes within instruments, and variations during sample extraction and
preparation. Sample degratation over time in long runs, oxidization or build-up
of contaminants can lead to signal drifts dependent on the injection order.

Different approaches for the normalization of metabolomics data exist (briefly
described also in [@Livera:2015bo]). Batch correction methods use per-feature
regression models to remove batch effects and signal drifts
[@Dunn:2011bq],[@Wang:2013fe],[@Wehrens:2016ie] but don't usually remove biases
related to the processing of individual samples (with the exception of Batch
Normalizer [@Wang:2013fe]). Other methods such as scaling (e.g. by the total sum
of signal) or RUV (removal of unwanted variance) [@Livera:2015bo] adjust for
such sample-specific biases, but do not remove feature specific signal drifts.

Combinations of such feature-wise and sample-wise normalization strategies
should be possible. Feature-wise normalization approaches, if applied before
normalization adjusting between sample differences, should however be based only
on QC samples, as these are thought to be (at least within the same batch),
independent of any sample processing differences.

## Experimental design and normalization strategy

The samples of the present experiment consist of samples blood samples that
were collected with mitra tips and stored at different periods of time under
differen circumstances.

QC samples, that are by design independent of the sample preparation step, can
be used to estimate and correct LC-MS specific biases, including a potential
injection order dependent signal drift and batch/run specific biases. Such
effects are thought to be specific for each metabolite. Sample preparation
dependent biases between samples (but independent of the metabolite) can be
estimated or evaluated using internal standards and replicated samples (two
samples for each individual and matrix).

It is not clear whether between-sample normalization should be performed before
or after adjustment for LC-MS specific biases. If batch and injection-order
dependent effects are adjusted using QC samples the order should not be
problematic as QC samples are independent of sample processing based
biases. Still, since biases related to the LC-MS system have been added to the
signal *after* biases related to sample processing, removing them first seems to
be more natural.

# Data import and initial quality assessment

First, we load all the required libraries and the preprocessed data. The
`quantify` method is then used to extract raw feature intensities from the
preprocessed data; we set the method to `sum` so that we sum the intensities
of all peaks detected for one feature in one sample. This function returns a
`SummarizedExperiment` object, where each column represents a sample and each
row contains a feature; this object can contain one or more matrices, in the
form of `assays`, which can be easily accessed with the `assay` function.
A `SummarizedExperiment` also allows us to retain annotation for each row and
column, which will later help us to subset columns and rows, in order to easily
access them with `colData` and `rowData`, respectively. Then, we assign
different colours to each experimental group, as we did for the preprocessing.

```{r libraries-data, message = FALSE, warning = FALSE}
library(xcms)
library(RColorBrewer)
library(pander)
library(SummarizedExperiment)
library(doParallel)
registerDoParallel(ncores)
register(DoparParam(), default = TRUE)
library(CompMetaboTools)
## Define colors for the groups.
col_storage <- brewer.pal(6, name = "Set1")
names(col_storage) <- c("4C_BAG",   # red
                        "RT",        # blue
                        "BAG",       # green
                        "VACUUM",    # purple
                        "4C_VACUUM", # orange
                        "QC")        # yellow
col_time <- brewer.pal(8, name = "Set3")
names(col_time) <- c("1d",
                     "1w",
                     "2d",
                     "2h",
                     "3d",
                     "6h",
                     "2w",
                     "QC")
load("data/RData/sts_preprocessing_pos/data_pos.RData")
```

Next we extract the feature abundances as a `SummarizedExperiment`, subsetting
also to the features defined above.

```{r extract-as-se}
res_pos <- quantify(data_pos, method = "sum", filled = FALSE)
```

# Gap filling and imputation of missing values

We fill-in data for samples in which no peak was detected. While we will
eventually exclude filled-in signals in the estimation of the normalization
factors for the within and between-batch normalization, we will normalize these
intensities as they might be affected by the same effects than the *real*
signal. Imputation of signals that are still missing after filling in will be
performed **after** normalization.

Many underlying causes can be at the root of these
missing intensities: a signal may be not detectable because a compound is absent
from a sample or it may be noisy (hence failing in the peak detection step to be
identified) and/or below the detection limit of the
instrument. We can use the `fillChromPeaks` function to rescue missing signals
with the so-called *gap filling*: this method uses the area under the curve of
the samples where the specific peak was identified to define plausible intensity
values where they are missing. We are then able to distinguish the filled-in
peaks from the detected peaks in the `chromPeakData` data frame: the
`"is_filled"` column is created, where `TRUE` will be annotated in case of
filled-in peaks. This information is added to `res_pos` as the `raw_filled`
assay: this will be later used to retrieve filled-in data only. It is important
to remember that even after gap filling, a signal can still be missing.

```{r fill-in, message = FALSE, warning = FALSE, eval = !file.exists(paste0(RDATA_PATH, "data_pos_filled.RData"))}
## Fill-in missing values
data_pos <- fillChromPeaks(data_pos, param = ChromPeakAreaParam())
save(data_pos, file = paste0(RDATA_PATH, "data_pos_filled.RData"))
```

```{r load, message = FALSE}
load(paste0(RDATA_PATH, "data_pos_filled.RData"))
## Add filled-in data to the result object
assays(res_pos)$raw_filled <- featureValues(data_pos, method = "sum",
                                            filled = TRUE)
## Add the only-filled-in signal to the result object
tmp <- assay(res_pos, "raw_filled")
tmp[!is.na(assay(res_pos, "raw"))] <- NA
assays(res_pos)$raw_only_filled <- tmp
```

Below we compare the signal distribution of detected and filled-in peak signals.

```{r compare-detected-filled-plot, fig.path = IMAGE_PATH, message = FALSE, echo = FALSE, warning = FALSE, fig.cap = "Distribution of (log2) signal intensities of detected and filled-in peaks. Left: all features/peaks, right: only peaks of features used in the present analysis based on the above definition.", fig.width = 8, fig.height = 4}
## Distribution raw data
ints_det <- chromPeaks(data_pos)[!chromPeakData(data_pos)$is_filled, "into"]
ints_fil <- chromPeaks(data_pos)[chromPeakData(data_pos)$is_filled, "into"]
par(mfrow = c(1, 2), mar = c(4, 4.5, 4, 0.5))
boxplot(list(detected = log2(ints_det), filled = log2(ints_fil)),
        varwidth = TRUE, main = "all peaks",
        ylab = expression(log[2]~abundance))
## Peaks assigned to features
pk_idxs <- sort(unlist(featureDefinitions(data_pos)[, "peakidx"]))
tmp <- chromPeaks(data_pos)[pk_idxs, "into"]
ints_det <- tmp[!chromPeakData(data_pos)$is_filled[pk_idxs]]
ints_fil <- tmp[chromPeakData(data_pos)$is_filled[pk_idxs]]
boxplot(list(detected = log2(ints_det), filled = log2(ints_fil)),
        varwidth = TRUE, main = "feature peaks",
        ylab = expression(log[2]~abundance))
```

As expected, abundances from filled-in peaks have on average lower intensities
than truly detected peaks. Abundances are however relatively similar suggesting
that for many missing peaks a signal from an ion was recorded, but peak
detection failed.

Afterwards, we compare the filled-in with the detected signal for *QC samples*.
We start by calculating the mean of both, then we proceed with plotting the
results. Ideally, the filled-in signal should be correlated to the detected
signal.

```{r correlation-filled-detected, fig.path = IMAGE_PATH, fig.cap = "Correlation of per-feature averaged detected and filled-in signal in QC samples.", echo = FALSE}
avg_det <- rowMeans(assay(res_pos, "raw")[, res_pos$storage == "QC"],
                    na.rm = TRUE)
avg_fil <- rowMeans(assay(res_pos, "raw_only_filled")[, res_pos$storage == "QC"],
                    na.rm = TRUE)
plot(log2(avg_det), log2(avg_fil), xlab = "detected", ylab = "filled-in",
     main = "Feature abundances, QC samples", pch = 16, col = "#00000080")
abline(0, 1, col = "grey")
cor(log2(avg_det), log2(avg_fil), use = "pairwise.complete.obs")
```

We can see a relatively high correlation between the detected and filled-in
signal, especially for features with higher abundances. For a considerable
amount of features the detected signal is however much higher than the
filled-in.

We now calculate and compare for each feature in QC samples the difference
between the detected and filled-in peak data. Evaluation in QC samples avoids
any potential differences being caused by biological differences of the compared
samples.

First, we plot the detected data:

```{r raw-boxplot-detected, fig.path =IMAGE_PATH, fig.cap = "Number of features and log2 abundance of raw detected data.", echo = FALSE}
dobox <- function(
 x, col = paste0(col_storage[as.character(data_pos$storage)], "ff"),
 outline = FALSE, notch = TRUE, range = 0,
 border = paste0(col_storage[as.character(data_pos$storage)], "60"),
 ylab = expression(log[2]~abundance), xaxt = "n", xlab = "",
 ...) {
 boxplot(x, col = col, outline = outline, notch = notch, range = range,
 border = border, ylab = ylab, xaxt = xaxt, xlab = xlab, ...)
 grid(nx = NA, ny = NULL)
}
layout(mat = matrix(1:2, ncol = 1), height = c(0.3, 0.7))
cols <- col_storage[as.character(res_pos$storage)]
par(mar = c(0.2, 4.5, 2, 0.5))
barplot(apply(assay(res_pos, "raw"), MARGIN = 2, function(x) sum(!is.na(x))),
        col = paste0(cols, 80), ylim = c(0, 10000),
        ylab = "Features", xaxt = "n", main = "Detected raw data")
legend("top", horiz = TRUE, col = col_storage, legend = names(col_storage),
       lwd = 1)
par(mar = c(0.2, 4.5, 0, 0.5))
dobox(log2(assay(res_pos, "raw")), col = paste0(cols, "ff"), xaxt = "n",
      border = paste0(cols, 60))
points(colMeans(log2(assay(res_pos, "raw")), na.rm = TRUE), type = "l")
grid(nx = NA, ny = NULL)
```

The number of detected peaks and the distribution of feature intensities seems
to be comparable between samples and storage methods. The high similarity of
average abundances between samples visible above might however be misleading,
since only signal from identified peaks are considered. Comparing signal
intensities **after** filling-in missing peak data might be better, because it
also reflects the fact that some features are simply not present in the data.

We thus plot next the complete data set (detected and filled-in signals):

```{r raw-boxplot-all, fig.path = IMAGE_PATH, fig.height = 7, fig.width = 7 * phi, fig.cap = "Number of features and log2 abundance of detected and filled-in data.", message = FALSE, echo = FALSE}
layout(mat = matrix(1:2, ncol = 1), height = c(0.3, 0.7))
cols <- col_storage[as.character(res_pos$storage)]
par(mar = c(0.2, 4.5, 2, 0.5))
barplot(apply(assay(res_pos, "raw_filled"), MARGIN = 2,
              function(x) sum(!is.na(x))),
        col = paste0(cols, 80), ylim = c(0, 15000),
        ylab = "Features", xaxt = "n", main = "Detected and filled-in raw data")
legend("top", horiz = TRUE, col = col_storage, legend = names(col_storage),
       lwd = 1)
par(mar = c(0.2, 4.5, 0, 0.5))
dobox(log2(assay(res_pos, "raw_filled")), col = paste0(cols, "ff"), xaxt = "n",
      border = paste0(cols, 60))
points(colMeans(log2(assay(res_pos, "raw_filled")), na.rm = TRUE), type = "l")
grid(nx = NA, ny = NULL)
```

From this image, we can conclude that most of the missing signals have been
rescued during the gap-filling step: the number of features, in fact, is
comparable among all samples. Some samples show however a slightly lower average
intensity.

To evaluate whether (raw) feature intensities are dependent on the storage
conditions we below average the 3 replicates per condition and compare the
signal distributions.

```{r raw-storage-condition, fig.path = IMAGE_PATH, fig.height = 7, fig.width = 7 * phi, fig.cap = "Distribution of average feature intensities for all storage conditions", echo = FALSE, message = FALSE}
res_pos$storage_time <- paste0(res_pos$storage, "_", res_pos$time)
res_pos$storage_time[res_pos$storage_time == "QC_QC"] <- "QC"

#' calculate average intensity across 3 replicates per condition
cond_ints <- lapply(sort(unique(res_pos$storage_time)), function(z) {
    rowMeans(log2(assay(res_pos, "raw_filled")[, res_pos$storage_time == z]),
             na.rm = TRUE)
})
names(cond_ints) <- sort(unique(res_pos$storage_time))
par(mar = c(8, 4.3, 1, 0.5))
boxplot(cond_ints, las = 2)
grid()
```

Some conditions, mostly for longer term storage, show a larger spread of signal.

We also plot the Relative Log Abundance (RLA) values for the raw data and for
data after gap filling; these will be later used to assess the efficiency of
normalization.

```{r raw-rla-plot, fig.path = IMAGE_PATH, fig.height = 7, fig.width = 7 * phi, fig.cap = "Relative Log Abundance (RLA) of raw data compared to the filled-in data.", echo = FALSE}
## RLA of raw data
par(mfrow = c(2, 1), mar = c(0.2, 4.5, 4.5, 0.5))
boxplot(xcms::rowRla(assay(res_pos, "raw"), group = res_pos$storage),
        cex = 0.5, pch = 16, col = col_storage[as.character(res_pos$storage)],
        border = paste0(col_storage[as.character(res_pos$storage)], 40),
        notch = TRUE, outline = FALSE, ylim = c(-6, 4),
        main = "Raw data", xaxt = "n", ylab = "RLA")
grid(nx = NA, ny = NULL)
## RLA after filling-in missing data
boxplot(xcms::rowRla(assay(res_pos, "raw_filled"), group = res_pos$storage),
        cex = 0.5, pch = 16, col = col_storage[as.character(res_pos$storage)],
        border = paste0(col_storage[as.character(res_pos$storage)], 40),
        notch = TRUE, outline = FALSE,
        main = "Filled-in data", xaxt = "n", ylab = "RLA")
grid(nx = NA, ny = NULL)
```


The RLA plot shows comparable RLA values for the raw data except for one sample
that was stored in a plastic bag.
After filling-in missing peak data the RLA values remain comparable across the
different storage methods.


## Internal standards

Internal standards are chemical species that resemble molecules in a sample, but
they have a distinct characteristic that helps us discriminate them from the
metabolites of interest (i.e. these internal standards are artificially modified
metabolites not occurring in a normal human sample). Internal standards are
added in the sample mix before data acquisition.

In the chunk code below, we load the table with the internal standards and their
expected mass-to-charge ratio m/z. Features detected at these m/z that also have
a retention time within a range of 30 seconds from the internal standard of
reference are then identified and their ID is added to the table.

```{r internal-standards-read, message = FALSE, warning = FALSE}
library(Rdisop)
library("MetaboCoreUtils")
is_info <- read.table(
    "https://raw.githubusercontent.com/EuracBiomedicalResearch/lcms-standards/master/data/internal_standards.txt",
    sep = "\t", header = TRUE, as.is = TRUE)
is_info <- is_info[!is.na(is_info$POS), ]
is_info$mass = NA
is_info$mz_ion = NA
for (i in seq(nrow(is_info))) {
    if (grepl("C", is_info$formula[i]))
        is_info$mass[i] <- getMolecule(is_info$formula[i])$exactmass
    else
        is_info$mass[i] = as.numeric(is_info$formula[i])
    #' Calculate also the m/z
    is_info$mz_ion[i] <- mass2mz(is_info$mass[i],
                                 adduct = is_info$POS[i])[1, 1]
}
is_info <- is_info[!is.na(is_info$mz_ion), ]
```

We next identify features potentially representing signal from the internal
standards by matching their expected m/z and retention time.

```{r}
library(MetaboAnnotation)
rowData(res_pos)$feature_id <- row.names(res_pos)
prm <- MzRtParam(tolerance = 0, ppm = 10, toleranceRt = 20)

is_data <- matchMz(res_pos, is_info, param = prm,
                   mzColname = c("mzmed", "mz_ion"),
                   rtColname = c("rtmed", "RT"))

#' subset to only matching features
is_data <- is_data[whichQuery(is_data)]
is_data <- pruneTarget(is_data)

```

We plot now the EIC for each identified internal standard:

```{r internal-standards-plot, echo = FALSE, message = FALSE, warning = FALSE}
#' For each internal standard, try to find features that overlap the m/z
#' and are close to the expected retention time.
is_chrs <- featureChromatograms(data_pos, features = is_data$feature_id,
                                expandRt = 5)
#' Plot the features for the internal standards.
col <- col_storage[as.character(is_chrs$storage)]
dr <- paste0(IMAGE_PATH, "internal-standards/")
dir.create(dr, showWarnings = FALSE)
for (i in seq_len(nrow(is_chrs))) {
    fn <- paste0(dr, gsub("%", "p", is_data$target_name[i]), "-",
                 is_data$feature_id[i], "_POS.png")
    chr <- is_chrs[i, ]
    cls <- col[chromPeaks(chr)[, "sample"]]
    png(fn, width = 16, height = 8, units = "cm", res = 200, pointsize = 4)
    plot(chr, peakBg = paste0(cls, 20),
         main = paste0(is_data$target_name[i], ": ",
                       format(mz(chr)[1], digits = 6), "-",
                       format(mz(chr)[2], digits = 6)),
         peakCol = paste0(cls, 60))
    abline(v = is_data$target_RT[i], lty = 2)
    dev.off()
}

is_data <- filterMatches(is_data,
                         queryValue = c("FT00393", "FT00393", "FT00392"),
                         targetValue = c("L-Isoleucine (13C6, 99%; 15N, 99%)",
                                         "L-Leucine (13C6, 99%; 15N, 99%)",
                                         "L-Leucine (13C6, 99%; 15N, 99%)"),
                         queryColname = "feature_id",
                         targetColname = "target_name",
                         keep = FALSE)
is_data <- is_data[whichQuery(is_data)]
is_data <- pruneTarget(is_data)
```

All features possibly related to internal standards (i.e. with a matching m/z
and a retention time within 20 seconds to the expected one) have been manually
evaluated and only features have been assigned to internal standards if the
signal was unambiguous.

All the plots were inspected and were considered of good quality.

The table below lists the internal standards and their assigned feature with
mean abundance and its standard deviation.

```{r, echo = FALSE, results = "asis"}
#' table of internal standards with mean and sd of abundances (in log2 scale)
tmp_fv <- assay(res_pos, "raw")[is_data$feature_id, ]
is_info <- target(is_data)
is_info$mean_abd <- rowMeans(log2(tmp_fv), na.rm = TRUE)
is_info$sd_abd <- rowSds(log2(tmp_fv), na.rm = TRUE)
is_info$RSD <- rowRsd(tmp_fv, na.rm = TRUE)
pandoc.table(is_info[, c("name", "mean_abd", "sd_abd", "RSD")],
             style = "rmarkdown", caption = "List of internal standards.")
```


# Between-sample normalization

Between-sample normalization aims to remove global abundance differences between
samples due to variations in sample collection, extraction, processing and
possibly amount. The simplest approach is to normalize abundances based on the
total sum of the signal or its median. Such approaches rely however on the
self-averaging property assuming that an increase in abundances of a group of
metabolites is balanced by a decrease in abundances in another group
[@Livera:2015bo]. Also, these approaches tend to be biased by highly abundant
metabolites. Methods robust against such a bias, like the median ratio method
(MRM [@Anders:2010fu]) or the trimmed mean of M-values (TMM [@Robinson:2010dd])
used in RNAseq data normalization could be used instead. In previous analyses
these methods had however a lower performance than the simple *median scaling*
which is thus used below.

Below we calculate normalization factors based on the the median abundance per
sample.

```{r estimate-norm-factors, echo = TRUE, message = FALSE, eval = TRUE}
## Calculate median and scaling factors
mdns <- apply(assay(res_pos, "raw_filled"), MARGIN = 2, median, na.rm = TRUE)
nf_mdn <- mdns / median(mdns)
```

```{r norm-factors-top-200, echo = FALSE, message = FALSE, eval = FALSE}
median_top_x <- function(x, top = 500) {
    idx <- order(x, decreasing = TRUE)
    median(x[idx][seq_len(top)], na.rm = TRUE)
}
mdns <- apply(assay(res_pos, "raw_filled"), MARGIN = 2,
              median_top_x, top = 1000)
nf_mdn <- mdns / median(mdns)
```

We next apply the *median scaling* normalization.

```{r normalization, echo = TRUE, message = FALSE}
## Perform normalization
assays(res_pos)$median_filled <- sweep(assay(res_pos, "raw_filled"),
                                       MARGIN = 2, nf_mdn, `/`)
```

We plot boxplots showing the data before and after between-sample normalization
to evaluate the outcome of the procedure:

```{r norm-boxplot-raw-median, fig.path = IMAGE_PATH, fig.height = 7, fig.width = 7, fig.cap = "Comparison of the boxplots before and after normalization by the median.", echo = FALSE, message = FALSE}
## Raw data_pos
par(mfrow = c(2, 1), mar = c(0.2, 4.5, 4.5, 0.5))
cols <- col_storage[as.character(res_pos$storage)]
## Before between-sample normalization
dobox(log2(assay(res_pos, "raw_filled")), col = paste0(cols, "ff"),
      xaxt = "n", border = paste0(cols, 60),
      main = "Before between-sample normalization")
points(colMeans(log2(assay(res_pos, "raw_filled")), na.rm = TRUE), type = "l")
grid(nx = NA, ny = NULL)
## After normalization by median
dobox(log2(assay(res_pos, "median_filled")), col = paste0(cols, "ff"),
      xaxt = "n", border = paste0(cols, 60),
      main = "After normalization by median")
points(colMeans(log2(assay(res_pos, "median_filled")), na.rm = TRUE),
       type = "l")
grid(nx = NA, ny = NULL)
```

Median scaling slightly reduced the differences in average intensities in the
data set.

We also generate RLA plots:

```{r norm-rla-plot, fig.path = IMAGE_PATH, fig.height = 7, fig.width = 7, fig.cap = "Comparison of RLA values before and after before and after normalization by the median.", message = FALSE, echo = FALSE}
## RLA for median normalization
par(mfrow = c(2, 1), mar = c(0.2, 4.5, 4.5, 0.5))
boxplot(xcms::rowRla(assay(res_pos, "raw_filled"), group = res_pos$storage),
        cex = 0.5, pch = 16, col = col_storage[as.character(res_pos$storage)],
        border = paste0(col_storage[as.character(res_pos$storage)], 40),
        notch = TRUE, outline = FALSE, ylim = c(-7, 5),
        xaxt = "n", ylab = "RLA", main = "Before between-sample normalization")
grid(nx = NA, ny = NULL)
boxplot(xcms::rowRla(assay(res_pos, "median_filled"), group = res_pos$storage),
        cex = 0.5, pch = 16, col = col_storage[as.character(res_pos$storage)],
        border = paste0(col_storage[as.character(res_pos$storage)], 40),
        notch = TRUE, outline = FALSE, ylim = c(-7, 5),
        xaxt = "n", ylab = "RLA", main = "After normalization by median")
grid(nx = NA, ny = NULL)
```

From the plot above, we can see that the normalization step performed so far
greatly helped in reducing variability.


# Within-batch normalization

Next we perform a within-batch normalization to remove potential injection order
dependent signal drifts. In order to define whether there is a similar injection
order dependent signal drift in each batch (i.e. the drift is independent of the
batch) we fit feature-wise linear models to the (log2 transformed) data of QC
samples within each batch and compare the slopes for each feature between the
batches.

Note that the models describing the batch effect and injection dependent signal
drift is estimated on the detected peak data, i.e. prior to filling-in missing
peak data.

Within-batch normalization is useful to remove injection-order-dependent signal
drifts: these discrepancies arise in the course of the analysis because the
intensity of the signal detected by the instrument changes with time
[@Wehrens:2016ie]. While the exact reason of this drift is unknown, it seems to
affect individual features differently.
Many algorithms have been developed to solve this problem, the best choice depends
on the type of data collected: internal standards, quality control samples
(QC), study samples or quality control metabolites [@Livera:2015bo].
For our analysis, we assume a log-linear time-dependent signal drift, thus we
have tried to fit three different subsets to the linear model `y ~ inj_idx`, to
find the better fit, based on the relative standard deviation (RSD). More
precisely, we tried to fit only the intensities of the detected features in the
QC samples, then we tried to fit all the features of the QC samples
(detected and filled-in) and finally we fit all the collected signals (i.e. QC
and study samples). The best result was obtained using only the detected QC
subset, which has been therefore used for further normalizing the data. Since
abundances in QC samples are not expected to differ between injections, we can
also safely assume that any changes seen on them are due to technical
variance. We are thus estimating the signal drift on the QC samples and
adjusting the study samples accordingly, assuming that the same bias affects
their feature abundance.

We also define below the variable `req_prop` to set the minimum range that the
injection indices must span to consider a fitting valid.

For the fitting of the normalization model we only use the QC samples:

```{r fit-model-plate, message = FALSE, warning = FALSE, echo = TRUE}
tmp <- log2(assay(res_pos, "median_filled"))
tmp[is.na(assay(res_pos, "raw"))] <- NA
mdls <- xcms:::rowFitModel(
                   y ~ injection_idx,
                   data = as.data.frame(
                          colData(res_pos)[res_pos$storage == "QC", ]),
                   y = tmp[, res_pos$storage == "QC"],
                   method = "lm",
                   minVals = 5)
req_prop <- 3/4
```

We next *flag* and remove fitted models we consider potentially problematic. In
particular, we remove models that were fitted to data points not spanning most
of the injection index range (e.g. models that were fitted to values with
injection indices from 1 to 20 or similar). In this case, we set `req_prop` to
`r req_prop`, meaning that the injection range of the signals used in the
fitting must span at least `r req_prop * 100`% of the total injection range;
the models for which this is not valid will be then removed.

Next, we calculate the slopes for each fitting and plot their distribution; we
highlight in blue the slopes of the features calculated with a low injection
range.

```{r estimate-slopes-per-batch, message = FALSE, warning = FALSE, fig.path = IMAGE_PATH, fig.cap = "Plot of per-feataure estimates for the injection order dependent signal drift.", fig.width = 6, fig.height = 6, echo = FALSE}
## Calculating flags
flgs_inj_range <- vapply(mdls, flag_model_inj_range, logical(1),
                         min_range = diff(range(res_pos$injection_idx))
                         * req_prop, column = "injection_idx")
## Calculate slopes for
slps <- vapply(mdls, function(z) {
    if (length(z) > 1) {
        coefficients(z)[2]
    } else NA_real_
}, numeric(1))
## Plot the distribution of slopes.
par(mar = c(4, 4.5, 1, 0.5))
hist(slps, breaks = 128, xlab = "slope", main = "Distribution of slopes")
hist(slps[which(flgs_inj_range)], breaks = 128, add = TRUE,
     col = "#0000ff80")
## Split into excluded and good mdls
mdls_inj_range <- mdls[which(flgs_inj_range)]
## Remove model fits for the flagged friends.
mdls[unique(which(flgs_inj_range))] <- NA
slps[unique(which(flgs_inj_range))] <- NA
## Identify the features that are adjusted
fts_adj <- sort(unique(c(
    names(mdls)[!is.na(mdls)],
    names(mdls)[!is.na(mdls)],
    names(mdls)[!is.na(mdls)]
)))
```

Most of the slopes, that represent the estimated injection order-dependent
signal drift, are close to 0 suggesting most features not being affected by this
bias.

The table below lists the number of features for which the model was fitted and
the number of features for which model fitting was skipped or discarded.

```{r fit-model-table, message = FALSE, echo = FALSE, results = "asis"}
tab <- cbind(c(length(mdls),
               length(which(flgs_inj_range)),
               sum(!is.na(mdls))))
rownames(tab) <- c("total features", "low inj idx range",
                   "valid model fits")
cptn <- paste("Numbers of features for which an injection index dependent",
              "model could be fitted.")
pandoc.table(tab, style = "rmarkdown", caption = cptn)
```

For half of all features a model describing the injection dependent signal drift
was defined.

Most of the slopes from the models describing the injection dependent signal
drift are close to 0 suggesting only a relatively low influence.

Finally, we apply the within batch correction adjusting all feature abundances
(also filled-in and imputed values) based on the estimated models. Adjustment
resulted in measurements with negative (log2) abundances. These were replaced
by half of the minimum non negative intensity for that feature. Note however
that quite some log2 abundances are smaller than 1, which represents negative
intensities in natural scale.

```{r apply-within-batch-adjustment, message = FALSE, warning = FALSE}
## Adjust the whole (filled-in) dataset
fv_adj <- assay(res_pos, "median_filled")
fv_adj <- xcms:::applyModelAdjustment(
                     y = log2(fv_adj),
                     lmod = mdls,
                     data = as.data.frame(colData(res_pos),
                     shiftNegative = "replaceHalfMin"))
assays(res_pos)$normalized_filled <- 2^fv_adj
```


# Final evaluation

We compare now the performances of the normalization steps, first plotting the
distribution of signal intensities of the filled-in raw data, the median-scaled
data and the normalized data.

Evaluation of the normalization performance can be done using different
samples/measurements of the present data set:
- sample pool (QC): the same sample measured repeatedly across the data
  set. Because it is a pool of all study sample it is an ideal *general
  representation* of the whole experiment.
  Also, if e.g. the injection order dependent signal drift is estimated on
  these pooled samples evaluating the performance of this normalization on them
  leads to biased (overly optimistic) performance indicators.
- internal standards: represent a set of artificial compounds added (in the same
  concentration) to each sample before sample preparation. For the present data
  set IS were added to the solvent solution in which the sample was solved from
  the Mitra tips. Hence, they do not allow to evaluate and compare the whole
  sample processing procedure (sampling) and would also not allow to detect
  differences in sample amount.


In this section we evaluate the performance of the individual normalization
steps using the above mentioned samples. As tools to evaluate the performance we
use the coefficient of variation (CV, also called relative standard deviation
RSD) which allows to estimate the variance of a feature's signal across
replicated measurements (across sample pools are for internal standards across
all samples). To evaluate differences between replicated samples we use the
Pearson's correlation coefficient and the 90% quantile of (log2) abundance
differences. Prior to the evaluation of the normalization performance we inspect
also the clustering of samples (and QCs) before and after normalization using
principal component analysis (PCA).

```{r PCA-raw-normalized, fig.path = IMAGE_PATH, fig.width = 9, fig.height = 9, fig.cap = "PCA of raw and normalized feature abundances.", echo = FALSE}
## Perform data imputation for PCA
assays(res_pos)$normalized_filled_imputed <-
                  imputeRowMinRand(assay(res_pos, "normalized_filled"),
                                   method = "from_to")
assays(res_pos)$raw_filled_imputed <-
                  imputeRowMinRand(assay(res_pos, "raw_filled"),
                                   method = "from_to")
pc_raw <- prcomp(t(log2(assay(res_pos, "raw_filled_imputed"))),
                 scale = FALSE, center = TRUE)
pc_norm <- prcomp(t(log2(assay(res_pos, "normalized_filled_imputed"))),
                  scale = FALSE, center = TRUE)
pch <- rep(21, ncol(res_pos))

par(mfrow = c(2, 2), mar = c(4, 4, 1, 0.5))
plot_pca(pc_raw, bg = paste0(col_storage[as.character(res_pos$storage)], 80),
         pc_x = 1, pc_y = 2, main = "raw data", pch = pch, col = "#00000080")
legend("topleft", col = col_storage, legend = names(col_storage), pch = 16,
       cex = 0.4)
plot_pca(pc_raw, bg = paste0(col_storage[as.character(res_pos$storage)], 80),
         pc_x = 3, pc_y = 4, main = "raw data", pch = pch, col = "#00000080")
plot_pca(pc_norm, bg = paste0(col_storage[as.character(res_pos$storage)], 80),
         pc_x = 1, pc_y = 2, main = "normalized data",
         pch = pch, col = "#00000080")
plot_pca(pc_norm, bg = paste0(col_storage[as.character(res_pos$storage)], 80),
         pc_x = 3, pc_y = 4, main = "normalized data",
         pch = pch, col = "#00000080")
```

The percentage of variance seen on PC1-PC4 remains almost the same after
normalizing the data. We can only observe some small changes in the clustering.

We also take a look at the PCA plot coloring the different storage time periods:

```{r PCA-raw-normalized_time, fig.path = IMAGE_PATH, fig.width = 9, fig.height = 9, fig.cap = "PCA of raw and normalized feature abundances.", echo = FALSE}
## Perform data imputation for PCA

par(mfrow = c(2, 2), mar = c(4, 4, 1, 0.5))
plot_pca(pc_raw, bg = paste0(col_time[as.character(res_pos$time)], 80),
         pc_x = 1, pc_y = 2, main = "raw data", pch = pch, col = "#00000080")
legend("topleft", col = col_time, legend = names(col_time), pch = 16,
       cex = 0.4)
plot_pca(pc_raw, bg = paste0(col_time[as.character(res_pos$time)], 80),
         pc_x = 3, pc_y = 4, main = "raw data", pch = pch, col = "#00000080")
plot_pca(pc_norm, bg = paste0(col_time[as.character(res_pos$time)], 80),
         pc_x = 1, pc_y = 2, main = "normalized data",
         pch = pch, col = "#00000080")
plot_pca(pc_norm, bg = paste0(col_time[as.character(res_pos$time)], 80),
         pc_x = 3, pc_y = 4, main = "normalized data",
         pch = pch, col = "#00000080")
```

Then, we take a closer look to the storage methods we are most interested in,
starting with the QC sample as we used them for the normalization step:

```{r PCA-raw-normalized-POOL, fig.path = IMAGE_PATH, fig.width = 9, fig.height = 9, fig.cap = "PCA of raw and normalized feature abundances for sample pools.", echo = FALSE}
tmp_ppool <- res_pos[, res_pos$storage == "QC"]
pc_raw_pool <- prcomp(t(log2(assay(tmp_ppool, "raw_filled_imputed"))),
                 scale = FALSE, center = TRUE)
pc_norm_pool <- prcomp(t(log2(assay(tmp_ppool, "normalized_filled_imputed"))),
                  scale = FALSE, center = TRUE)
pch <- rep(21, ncol(res_pos))

par(mfrow = c(2, 2), mar = c(4, 4, 1, 0.5))
plot_pca(pc_raw_pool, bg = paste0(col_storage[as.character(tmp_ppool$storage)], 80),
         pc_x = 1, pc_y = 2, main = "raw data, pool",
         pch = pch, col = "#00000080")
legend("topleft", col = col_storage, legend = names(col_storage), pch = 16,
       cex = 0.4)
plot_pca(pc_raw_pool, bg = paste0(col_storage[as.character(tmp_ppool$storage)], 80),
         pc_x = 3, pc_y = 4, main = "raw data, pool",
         pch = pch, col = "#00000080")
plot_pca(pc_norm_pool, bg = paste0(col_storage[as.character(tmp_ppool$storage)], 80),
         pc_x = 1, pc_y = 2, main = "normalized data, pool",
         pch = pch, col = "#00000080")
plot_pca(pc_norm_pool, bg = paste0(col_storage[as.character(tmp_ppool$storage)], 80),
         pc_x = 3, pc_y = 4, main = "normalized data, pool",
         pch = pch, col = "#00000080")
```

The QC samples show a clear distinction in PC1 when looked at them separatedly.
We then look at the samples that were stored at room temperature:

```{r PCA-raw-normalized-rt, fig.path = IMAGE_PATH, fig.width = 9, fig.height = 9, fig.cap = "PCA of raw and normalized feature abundances for samples stored at room temperature.", echo = FALSE}
tmp_rt <- res_pos[, res_pos$storage == "RT"]
pc_raw_rt <- prcomp(t(log2(assay(tmp_rt, "raw_filled_imputed"))),
                 scale = FALSE, center = TRUE)
pc_norm_rt <- prcomp(t(log2(assay(tmp_rt, "normalized_filled_imputed"))),
                  scale = FALSE, center = TRUE)
pch <- rep(21, ncol(res_pos))
par(mfrow = c(2, 2), mar = c(4, 4, 1, 0.5))
plot_pca(pc_raw_rt, bg = paste0(col_time[as.character(tmp_rt$time)], 80),
         pc_x = 1, pc_y = 2, main = "raw data, rt", pch = pch, col = "#00000080")
legend("topleft", col = col_time, legend = names(col_time), pch = 16,
       cex = 0.4)
plot_pca(pc_raw_rt, bg = paste0(col_time[as.character(tmp_rt$time)], 80),
         pc_x = 3, pc_y = 4, main = "raw data, rt",
         pch = pch, col = "#00000080")
plot_pca(pc_norm_rt, bg = paste0(col_time[as.character(tmp_rt$time)], 80),
         pc_x = 1, pc_y = 2, main = "normalized data, rt",
         pch = pch, col = "#00000080")
plot_pca(pc_norm_rt, bg = paste0(col_time[as.character(tmp_rt$time)], 80),
         pc_x = 3, pc_y = 4, main = "normalized data, rt",
         pch = pch, col = "#00000080")
```

Next, we take a look at the PCA analysis of samples stored in plastic bags
together with dessicants:

```{r PCA-raw-normalized-bag, fig.path = IMAGE_PATH, fig.width = 9, fig.height = 9, fig.cap = "PCA of raw and normalized feature abundances for samples stored in plastic bags.", echo = FALSE}
tmp_bag <- res_pos[, res_pos$storage == "BAG"]
pc_raw_bag <- prcomp(t(log2(assay(tmp_bag, "raw_filled_imputed"))),
                 scale = FALSE, center = TRUE)
pc_norm_bag <- prcomp(t(log2(assay(tmp_bag, "normalized_filled_imputed"))),
                  scale = FALSE, center = TRUE)
pch <- rep(21, ncol(res_pos))

par(mfrow = c(2, 2), mar = c(4, 4, 1, 0.5))
plot_pca(pc_raw_bag, bg = paste0(col_time[as.character(tmp_bag$time)], 80),
         pc_x = 1, pc_y = 2, main = "raw data, bag",
         pch = pch, col = "#00000080")
legend("topleft", col = col_time, legend = names(col_time), pch = 16,
       cex = 0.4)
plot_pca(pc_raw_bag, bg = paste0(col_time[as.character(tmp_bag$time)], 80),
         pc_x = 3, pc_y = 4, main = "raw data, bag",
         pch = pch, col = "#00000080")
plot_pca(pc_norm_bag, bg = paste0(col_time[as.character(tmp_bag$time)], 80),
         pc_x = 1, pc_y = 2, main = "normalized data, bag",
         pch = pch, col = "#00000080")
plot_pca(pc_norm_bag, bg = paste0(col_time[as.character(tmp_bag$time)], 80),
         pc_x = 3, pc_y = 4, main = "normalized data, bag",
         pch = pch, col = "#00000080")
```

Lastly, we plot the raw and normalized feature abundances for the internal
standards:

```{r PCA-raw-normalized-IS, fig.path = IMAGE_PATH, fig.width = 9, fig.height = 9, fig.cap = "PCA of raw and normalized feature abundances for internal standards." , echo = FALSE}
pc_raw <- prcomp(
    t(log2(assay(res_pos, "raw_filled_imputed")[is_data$feature_id, ])),
    scale = FALSE, center = TRUE)
pc_norm <- prcomp(
    t(log2(assay(res_pos, "normalized_filled_imputed")[is_data$feature_id, ])),
    scale = FALSE, center = TRUE)
pch <- rep(21, ncol(res_pos))

par(mfrow = c(2, 2), mar = c(4, 4, 1, 0.5))
plot_pca(pc_raw, bg = paste0(col_storage[as.character(res_pos$storage)], 80),
         pc_x = 1, pc_y = 2, main = "raw data IS", pch = pch, col = "#00000080")
legend("bottomleft", col = col_storage, legend = names(col_storage), pch = 16,
       cex = 0.4)
plot_pca(pc_raw, bg = paste0(col_storage[as.character(res_pos$storage)], 80),
         pc_x = 3, pc_y = 4, main = "raw data IS", pch = pch, col = "#00000080")
plot_pca(pc_norm, bg = paste0(col_storage[as.character(res_pos$storage)], 80),
         pc_x = 1, pc_y = 2, main = "normalized data IS",
         pch = pch, col = "#00000080")
plot_pca(pc_norm, bg = paste0(col_storage[as.character(res_pos$storage)], 80),
         pc_x = 3, pc_y = 4, main = "normalized data IS",
         pch = pch, col = "#00000080")
```

87% of the variance in feature abundance for the internal standards can be
seen on PC1 plot of the raw data, after normalization we see a loosened cluster
on PC3 and PC4.

We then plot the log2 abundances of raw, median-scaled and normalized data:

```{r boxplot-after-within-normalization, fig.path = IMAGE_PATH, fig.height = 10, fig.width = 8, fig.cap = "Comparison between abundances (log2) of raw data, median-scaled data and normalized data.", message = FALSE, echo = FALSE}
##Raw data
par(mfrow = c(3, 1), mar = c(0.2, 4.5, 4.5, 0.5))
cols <- col_storage[as.character(res_pos$storage)]
dobox(log2(assay(res_pos, "raw_filled")), col = paste0(cols, "ff"),
      xaxt = "n", border = paste0(cols, 60), main = "Raw data")
points(colMeans(log2(assay(res_pos, "raw_filled")), na.rm = TRUE), type = "l")
grid(nx = NA, ny = NULL)
## Median normalized
dobox(log2(assay(res_pos, "median_filled")), col = paste0(cols, "ff"),
      xaxt = "n", border = paste0(cols, 60), main = "Median-scaled data")
points(colMeans(log2(assay(
                     res_pos, "median_filled")), na.rm = TRUE), type = "l")
grid(nx = NA, ny = NULL)
## Final normalized data
dobox(log2(assay(res_pos, "normalized_filled")), col = paste0(cols, "ff"),
      xaxt = "n", border = paste0(cols, 60),
      main = "Within-batch normalized data")
points(colMeans(log2(assay(res_pos, "normalized_filled")), na.rm = TRUE),
       type = "l")
grid(nx = NA, ny = NULL)
```

From the plots, we can see that most of the improvement comes from the
normalization by the median; only a few slight changes are visible after the
linear fitting.

Next, we plot the RLA of the whole dataset and of the internal standards to
confirm the current hypotheses:

```{r rla-after-between-normalization, fig.path = IMAGE_PATH, fig.height = 10, fig.width = 8, fig.cap = "RLA of raw data, median-scaled data and normalized data.", message = FALSE, echo = FALSE}
## Raw data
par(mfrow = c(3, 1), mar = c(0.2, 4.5, 4.5, 0.5))
boxplot(xcms::rowRla(assay(res_pos, "raw_filled"), group = res_pos$storage),
        cex = 0.5, pch = 16, col = col_storage[as.character(res_pos$storage)],
        border = paste0(col_storage[as.character(res_pos$storage)], 40),
        notch = TRUE, outline = FALSE, ylim = c(-7, 5),
        xaxt = "n", ylab = "RLA", main = "Raw data")
grid(nx = NA, ny = NULL)
## Median scaled data
boxplot(xcms::rowRla(assay(res_pos, "median_filled"), group = res_pos$storage),
        cex = 0.5, pch = 16, col = col_storage[as.character(res_pos$storage)],
        border = paste0(col_storage[as.character(res_pos$storage)], 40),
        notch = TRUE, outline = FALSE, ylim = c(-7, 5),
        xaxt = "n", ylab = "RLA", main = "Median-scaled data")
grid(nx = NA, ny = NULL)
## Normalized data
boxplot(xcms::rowRla(assay(res_pos, "normalized_filled"),
                     group = res_pos$storage),
        cex = 0.5, pch = 16, col = col_storage[as.character(res_pos$storage)],
        border = paste0(col_storage[as.character(res_pos$storage)], 40),
        notch = TRUE, outline = FALSE, ylim = c(-7, 5),
        xaxt = "n", ylab = "RLA", main = "Within-batch normalized data")
grid(nx = NA, ny = NULL)
```

From the RLA plots we can observe the same thing seen above: most changes
occurred after normalization by the median. This is also confirmed after looking
at the RLA plot of the internal standards, which exhibit a similar behaviour.


Finally, we compute the coefficient of variation (CV or relative standard
deviation RSD) for each feature in POOL and study samples, and also for internal
standards, both in POOL and study samples. We plot then boxplots and show in a
table how the RSD changes across the different groups.

```{r RSD-POOL, message = FALSE, echo = FALSE, warning = FALSE}
## Calculate RSD on all POOL signals
rsd_raw <- rowRsd(
    assay(res_pos, "raw_filled")[, res_pos$storage == "QC"])
rsd_scl <- rowRsd(
    assay(res_pos, "median_filled")[, res_pos$storage == "QC"])
rsd_bbn <- rowRsd(
    assay(res_pos, "normalized_filled")[, res_pos$storage == "QC"])
```

```{r RSD-study-samples, message = FALSE, echo = FALSE, warning = FALSE}
## Calculate RSD on all study samples
rsd_raw_sts <- rowRsd(
    assay(res_pos, "raw_filled")[, res_pos$storage != "QC"])
rsd_scl_sts <- rowRsd(
    assay(res_pos, "median_filled")[, res_pos$storage != "QC"])
rsd_bbn_sts <- rowRsd(
    assay(res_pos, "normalized_filled")[, res_pos$storage != "QC"])
```

```{r RSD-internal-standards, message = FALSE, echo = FALSE, warning = FALSE}
## Calculate RSD on internal standards in POOL signals
tmp_is <- assay(res_pos, "raw_filled")[is_data$feature_id, ]
rsd_raw_is <- rowRsd(tmp_is[, res_pos$storage == "QC"])
tmp_is <- assay(res_pos, "median_filled")[is_data$feature_id, ]
rsd_scl_is <- rowRsd(tmp_is[, res_pos$storage == "QC"])
tmp_is <- assay(res_pos, "normalized_filled")[is_data$feature_id, ]
rsd_bbn_is <- rowRsd(tmp_is[, res_pos$storage == "QC"])
## Calculate RSD on good internal standards in study samples
tmp_is <- assay(res_pos, "raw_filled")[is_data$feature_id, ]
rsd_raw_is_sts <- rowRsd(tmp_is[, res_pos$storage != "QC"])
tmp_is <- assay(res_pos, "median_filled")[is_data$feature_id, ]
rsd_scl_is_sts <- rowRsd(tmp_is[, res_pos$storage != "QC"])
tmp_is <- assay(res_pos, "normalized_filled")[is_data$feature_id, ]
rsd_bbn_is_sts <- rowRsd(tmp_is[, res_pos$storage != "QC"])
```

```{r norm-rsd-plot, fig.path = IMAGE_PATH, message = FALSE, echo = FALSE, fig.height = 7, fig.width = 7 * phi, fig.cap = "Coefficient Of Variation (RSD)."}
par(mfrow = c(2, 2))
boxplot(list(raw = rsd_raw, scaled = rsd_scl,
             normalized = rsd_bbn),
        main = "All features - POOL samples")
grid(nx = NA, ny = NULL)
abline(h = 0.3)
boxplot(list(raw = rsd_raw_sts, scaled = rsd_scl_sts,
             normalized = rsd_bbn_sts),
        main = "All features - Study samples")
grid(nx = NA, ny = NULL)
abline(h = 0.3)
boxplot(list(raw = rsd_raw_is, scaled = rsd_scl_is,
             normalized = rsd_bbn_is),
        main = "IS features - POOL samples")
grid(nx = NA, ny = NULL)
abline(h = 0.3)
boxplot(list(raw = rsd_raw_is_sts, scaled = rsd_scl_is_sts,
             normalized = rsd_bbn_is_sts),
        main = "IS features - Study samples")
grid(nx = NA, ny = NULL)
abline(h = 0.3)
```

The table below lists the results.

```{r final-qa-rsd-table, message = FALSE, echo = FALSE, results = "asis", warning = FALSE}
T <- rbind(
    `QC samples, RSD` = c(raw = mean(rsd_raw, na.rm = TRUE),
                          scaled = mean(rsd_scl, na.rm = TRUE),
                          `within-batch` = mean(rsd_bbn, na.rm = TRUE)),
    `study samples, RSD` = c(raw = mean(rsd_raw_sts, na.rm = TRUE),
                             scaled = mean(rsd_scl_sts, na.rm = TRUE),
                             `within-batch` = mean(rsd_bbn_sts, na.rm = TRUE)),
    `IS QC, RSD` = c(raw = mean(rsd_raw_is, na.rm = TRUE),
                     scaled = mean(rsd_scl_is, na.rm = TRUE),
                     `within-batch` = mean(rsd_bbn_is, na.rm = TRUE)),
    `IS study, RSD` = c(raw = mean(rsd_raw_is_sts, na.rm = TRUE),
                        scaled = mean(rsd_scl_is_sts, na.rm = TRUE),
                        `within-batch` = mean(rsd_bbn_is_sts, na.rm = TRUE)),
    `QC samples, %RSD > 0.3` = c(sum(rsd_raw > 0.3, na.rm = TRUE),
                                 sum(rsd_scl > 0.3, na.rm = TRUE),
                                 sum(rsd_bbn > 0.3, na.rm = TRUE)) *
        100 / length(rsd_raw),
    `study samples, %RSD > 0.3` = c(sum(rsd_raw_sts > 0.3, na.rm = TRUE),
                                    sum(rsd_scl_sts > 0.3, na.rm = TRUE),
                                    sum(rsd_bbn_sts > 0.3, na.rm = TRUE)) *
        100 / length(rsd_raw_sts),
    `IS QC, %RSD > 0.3` = c(sum(rsd_raw_is > 0.3, na.rm = TRUE),
                            sum(rsd_scl_is > 0.3, na.rm = TRUE),
                            sum(rsd_bbn_is > 0.3, na.rm = TRUE)) *
        100 / length(rsd_raw_is),
    `IS study, %RSD > 0.3` = c(sum(rsd_raw_is_sts > 0.3, na.rm = TRUE),
                               sum(rsd_scl_is_sts > 0.3, na.rm = TRUE),
                               sum(rsd_bbn_is_sts > 0.3, na.rm = TRUE)) *
        100 / length(rsd_raw_is_sts)
)
cpt <- paste0("Summary of RSD calculations. We show how the RSD changes among ",
              "different groups: all features in POOL samples, only detected ",
              "signals in POOL samples, all features in study samples, ",
              "internal standards in POOL samples and internal standards in ",
              "study samples.")
pandoc.table(T, caption = cpt, style = "rmarkdown")
```

From what we see, there is an improvement in RSD from raw to normalized data in
the QC samples: this outcome is desired, though also biased, as we fit our
data to these signals. The RSD of study samples is, as expected, much larger
than the RSD of QC samples. Normalization does not reduce the variance between
study samples, which is desired as any reduction might reduce also biological
variance. Unexpectedly, the RSD for internal standards is much larger in study
samples than in QC samples.


At last missing values were imputed and the result object saved.

```{r}
assays(res_pos)$normalized_filled_imputed <-
                  imputeRowMinRand(assay(res_pos, "normalized_filled"),
                                   method = "from_to")
save(res_pos, file = paste0(RDATA_PATH, "res_pos.RData"))
```



# Session information

The versions of R and the individually used packges are listed below.

```{r}
sessionInfo()
```

# References